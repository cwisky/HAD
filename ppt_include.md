#  Presentation 포함 사항

## 실험 개요
* 전체내용 : 실험순서에 따른 툴 및 실험환경 소개 및 실험절차와 입증한 사실
  + 모델 1, 2, 3 생성과 성능측정 지표 및 입증 사실 순으로 작성
* 목표 : 실제 비디오만 학습한 LSTM모델보다 Blender가 생성한 합성 비디오가 더해지면 모델의 정확도가 높다
* 실험 방법: 3개의 모델을 생성하고 학습하여 실제 비디오를 걷기/달리기로 분류하는 성능 측정
* 모델별 학습 데이터 구성
  + model 1 : 실제 비디오(걷기,달리기) / 반전 비디오로 학습
  + model 2 : model1 데이터 + Blender 합성 비디오(걷기/달리기)
  + model 3 : model2 데이터 + Blender에서 관절 각도에 변이를 적용한 2개의 비디오(걷기/달리기)

## 실험환경 구성
* Blender4.1 소개, 다운로드 및 설치
* Blender4.1에 numpy, pandas 설치법
* Google Colab & Google Drive

## Model 1 생성 및 성능 측정 절차
* 학습용 실제 비디오 다운로드(사이트 소개 포함)
* Blender4.1에서 학습용 실제 비디오의 해상도, fps, 프레임 수 조정
* Blender4.1에서 학습용 실제 비디오 원본 반전으로 mp4생성
* 원본 비디오로부터 Mediapipe를 사용하여 관절좌표 추출(csv)
* Mediapipe의 기능 및 추출된 좌표의 의미(체계)
* 달리기, 걷기를 결정하는 주요 관절과 mediapipe 랜드마크
* 원본 비디오에서 추출된 관절좌표 CSV 일부 소개
* LSTM학습용 시퀀스 데이터로 가공법 및 Sliding Window 소개
* LSTM모델의 중요개념 및 학습시의 가중치(학습의 의미)
* 원본 비디오 학습에 사용된 코드 및 실행환경 소개(Model1)
* 학습내역 차트 및 Early Stop 및 CheckPoint 설정의 필요성
* 원본으로 학습된 LSTM 모델의 로드 및 실제 비디오 분류
* 분류 결과 생성된 보고서(csv)
* 분류 결과 보고서를 활용한 성능측정 지표(수치 및 차트)

## Model 2 생성 및 성능 측정 절차
* mixamo 애니메이션(fbx) 선택 및 다운로드(걷기, 달리기)
* Blender4.1에서 fbx의 해상도,fps, 프레임수, 배경색 설정
* Blender4.1에서 fbx(걷기, 달리기) 애니메이션을 mp4로 변환
* 변환된 mp4 비디오를 좌우반전하여 mp4 파생 비디오 생성
* 파생 비디오에서 mediapipe를 사용하여 관절좌표 추출(csv)
* 실제 비디오 데이터 + 파생 비디오 데이터를 LSTM학습 시퀀스로 전처리
* 실제 비디오 + 파생 비디오 데이터를 사용한 Model2 학습
* Model2 학습내역 차트 및 특징
* Model2의 성능측정지표 제시

## Model 3 생성 및 성능 측정 절차
* Blender에서 걷기, 달리기 fbx 비디오 인체관절 각도 조작(0.9, 1.3)
* 관절 조작된 애니메이션의 mp4 비디오 생성 및 반전 비디오 생성
* 조작된 비디오로부터 Mediapipe를 사용하여 관절좌표 추출/csv
* 전처리, z값 제거
* 실제비디오, 애니메이션 변환 비디오, 관절조작 비디오 합치기
* Model3를 위한 시퀀스 생성
* Model3 학습 및 학습내역 차트, 특징
* Model3의 실제 비디오 분류 성능 테스트 및 성능측정 지표

## 3개의 모델 비교
* Model1,2,3의 성능측정 지표 비교
* 실험을 통해 입증된 것

## 부록 소개
* Github 실험 자료 소개

## Thanks
